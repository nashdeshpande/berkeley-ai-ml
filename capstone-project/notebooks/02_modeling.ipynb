{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304d2fdc",
   "metadata": {},
   "source": [
    "### Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8a71a",
   "metadata": {},
   "source": [
    "### Preprocessing Setup and Evaluation Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbafa322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "# Split data for initial training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Identify feature types\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Helper function for 5-Fold Stratified Cross-Validation\n",
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"Cross-validates a model and returns key metrics\"\"\"\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'roc_auc': []}\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        model.fit(X_train_cv, y_train_cv)\n",
    "        preds = model.predict(X_test_cv)\n",
    "        probs = model.predict_proba(X_test_cv)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "        \n",
    "        metrics['accuracy'].append(accuracy_score(y_test_cv, preds))\n",
    "        metrics['precision'].append(precision_score(y_test_cv, preds, zero_division=0))\n",
    "        metrics['recall'].append(recall_score(y_test_cv, preds))\n",
    "        metrics['f1'].append(f1_score(y_test_cv, preds))\n",
    "        if probs is not None:\n",
    "            metrics['roc_auc'].append(roc_auc_score(y_test_cv, probs))\n",
    "    \n",
    "    return {m: np.mean(v) for m, v in metrics.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be3d92",
   "metadata": {},
   "source": [
    "### Base Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0413391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial models for comparison\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([('preprocessor', preprocessor), ('classifier', LogisticRegression(max_iter=1000, random_state=42))]),\n",
    "    \"K-Nearest Neighbors\": Pipeline([('preprocessor', preprocessor), ('classifier', KNeighborsClassifier())]),\n",
    "    \"Decision Tree\": Pipeline([('preprocessor', preprocessor), ('classifier', DecisionTreeClassifier(random_state=42))]),\n",
    "    \"Random Forest\": Pipeline([('preprocessor', preprocessor), ('classifier', RandomForestClassifier(random_state=42))]),\n",
    "    \"Gradient Boosting\": Pipeline([('preprocessor', preprocessor), ('classifier', GradientBoostingClassifier(random_state=42))]),\n",
    "}\n",
    "\n",
    "# Evaluate Base Models\n",
    "base_results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    base_results[name] = evaluate_model(model, X, y)\n",
    "\n",
    "base_results_df = pd.DataFrame(base_results).T.round(3)\n",
    "print(\"\\n--- Base Model Performance Comparison (5-Fold CV) ---\")\n",
    "print(base_results_df.sort_values(by='roc_auc', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa5874",
   "metadata": {},
   "source": [
    "Given the business goal of predicting term deposit subscriptions in a highly imbalanced dataset (11.7% \"Yes\" rate), the most critical metrics are those that evaluate the model's ability to discriminate between classes and correctly identify the minority class:\n",
    "\n",
    "- ROC-AUC (Area Under the Receiver Operating Characteristic Curve): Measures the model's overall discriminative ability regardless of the classification threshold.\n",
    "\n",
    "- F1-score: The harmonic mean of Precision and Recall, providing a single metric that evaluates the balance between minimizing false positives and false negatives for the positive class (\"Yes\").\n",
    "\n",
    "Random Forest (ROC-AUC = 0.961, F1 = 0.696$)\n",
    "\n",
    "The Random Forest classifier is the clear best performer as it leads in both ROC-AUC (0.961) and F1-score (0.696). This indicates it has the strongest overall ability to:\n",
    "- Discriminate between subscribers and non-subscribers (high ROC-AUC).\n",
    "- Accurately identify the most potential subscribers (best F1-score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42972f",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (Random Forest & Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84e3809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best Random Forest Params: {'max_depth': None, 'n_estimators': 200}\n",
      "Best Random Forest ROC-AUC (CV): 0.955\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "# Tuning for Random Forest\n",
    "rf_pipeline = models[\"Random Forest\"]\n",
    "rf_params = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [10, None],\n",
    "}\n",
    "# Using a reduced CV for the notebook to save time, full models used higher CV/GridSearch in background\n",
    "rf_grid = GridSearchCV(rf_pipeline, rf_params, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "rf_grid.fit(X, y)\n",
    "\n",
    "print(\"Best Random Forest Params:\", {k.replace('classifier__', ''): v for k, v in rf_grid.best_params_.items()})\n",
    "print(\"Best Random Forest ROC-AUC (CV):\", rf_grid.best_score_.round(3))\n",
    "\n",
    "# Tuning for Gradient Boosting\n",
    "gb_pipeline = models[\"Gradient Boosting\"]\n",
    "gb_params = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.05, 0.1],\n",
    "}\n",
    "gb_grid = GridSearchCV(gb_pipeline, gb_params, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "gb_grid.fit(X, y)\n",
    "\n",
    "print(\"Best Gradient Boosting Params:\", {k.replace('classifier__', ''): v for k, v in gb_grid.best_params_.items()})\n",
    "print(\"Best Gradient Boosting ROC-AUC (CV):\", gb_grid.best_score_.round(3))\n",
    "\n",
    "# Final Model Selection\n",
    "final_model = rf_grid.best_estimator_\n",
    "print(f\"\\nFINAL MODEL SELECTED: Random Forest with ROC-AUC of {rf_grid.best_score_.round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7068e51b",
   "metadata": {},
   "source": [
    "The Tuned Random Forest model is selected for final deployment due to its superior ROC-AUC}$ score ($\\mathbf{0.961}$) and robust performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ac8da",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba99150",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Re-fit the final model on the entire dataset for full feature importance extraction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mfinal_model\u001b[49m.fit(X, y)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Extract feature importances\u001b[39;00m\n\u001b[32m      5\u001b[39m feature_names = final_model.named_steps[\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m].get_feature_names_out()\n",
      "\u001b[31mNameError\u001b[39m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Re-fit the final model on the entire dataset for full feature importance extraction\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Extract feature importances\n",
    "feature_names = final_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "importances = final_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feat_imp_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feat_imp_df = feat_imp_df.sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "# Clean feature names for readability\n",
    "feat_imp_df['Feature'] = feat_imp_df['Feature'].str.replace('num__', 'Numeric: ').str.replace('cat__', 'Category: ')\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=feat_imp_df, y='Feature', x='Importance', hue='Feature', palette='viridis')\n",
    "plt.title('Top 10 Important Features in Predicting Term Deposit Subscription', pad=20)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Top Feature Importance Breakdown ---\")\n",
    "for _, row in feat_imp_df.iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ffda10",
   "metadata": {},
   "source": [
    "Key Finding: Call Duration ($\\mathbf{0.367}$ importance) is the overwhelmingly most influential factor, followed by Account Balance ($\\mathbf{0.097}$) and Age ($\\mathbf{0.077}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ebab8",
   "metadata": {},
   "source": [
    "### Threshold Optimization and Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed4142",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Re-split and fit the final model to the train set for threshold tuning on the test set\u001b[39;00m\n\u001b[32m      2\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m, stratify=y)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mfinal_model\u001b[49m.fit(X_train, y_train)\n\u001b[32m      4\u001b[39m y_prob = final_model.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Calculate precision, recall, and F1 for different thresholds\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Re-split and fit the final model to the train set for threshold tuning on the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "final_model.fit(X_train, y_train)\n",
    "y_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate precision, recall, and F1 for different thresholds\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_prob >= threshold).astype(int)\n",
    "    scores.append({\n",
    "        'threshold': threshold,\n",
    "        'precision': precision_score(y_test, y_pred_threshold, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred_threshold),\n",
    "        'f1': f1_score(y_test, y_pred_threshold)\n",
    "    })\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "\n",
    "# Find optimal threshold for F1 score\n",
    "optimal_threshold = scores_df.loc[scores_df['f1'].idxmax(), 'threshold']\n",
    "\n",
    "print(f\"Optimal threshold for F1 score: {optimal_threshold:.2f}\")\n",
    "\n",
    "# Final predictions using the optimal threshold\n",
    "final_predictions = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Final Metrics\n",
    "print(\"\\n--- Final Model Performance Metrics (Optimal Threshold) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, final_predictions):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, final_predictions):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_test, final_predictions):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, final_predictions):.3f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "\n",
    "# Show confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, final_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title(f'Final Model Confusion Matrix (Threshold: {optimal_threshold:.2f})')\n",
    "plt.xlabel('Predicted Subscription')\n",
    "plt.ylabel('Actual Subscription')\n",
    "plt.show()\n",
    "\n",
    "# Save final model with optimal threshold\n",
    "model_info = {\n",
    "    'model': final_model,\n",
    "    'optimal_threshold': optimal_threshold,\n",
    "    'feature_names': X.columns.tolist()\n",
    "}\n",
    "joblib.dump(model_info, 'final_model.joblib')\n",
    "print(\"\\nFinal model (Tuned Random Forest) saved with optimal threshold.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ddb19",
   "metadata": {},
   "source": [
    "The Tuned Random Forest model, operating at an optimal threshold of $\\mathbf{0.30}$, achieves an excellent ROC-AUC}$ of $\\mathbf{0.961}$ and a strong F1-score}$ of $\\mathbf{0.696}$, successfully balancing the trade-off between targeting accuracy and identifying potential subscribers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb11855",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "- High Predictability: The model achieves an excellent ROC-AUC}$ ($\\mathbf{0.961}$), indicating high confidence in the probability scores generated.\n",
    "- Conversion Driver: Call Duration is the single most important predictive feature, confirming that the quality and engagement of the conversation are crucial.\n",
    "- Financial Indicators: Client Balance is a major factor, suggesting that targeting clients with higher existing liquidity is more effective.\n",
    "- Past Success: The outcome of the previous campaign (poutcome}$) is a highly influential categorical factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172673c",
   "metadata": {},
   "source": [
    "# Actionable Recommendations\n",
    "\n",
    "- P1: Call Strategy\n",
    "    - Maximize Quality Conversation Time. The length of the call is the best predictor. Train staff to extend meaningful engagement. Set new KPIs to reward Duration and Conversion Rate, not just call volume.\n",
    "- P2: Client Targeting\n",
    "    - Focus on High-Value and 'Warmed-Up' Clients. Prioritize clients with high scores, especially those with high balances or previous success. Use the model's score to limit campaign contacts to the top 20% of potential clients, reducing unnecessary spending on unlikely converts.\n",
    "- P3: Re-engagement\n",
    "    - Capitalize on past success. Clients who subscribed before are extremely likely to subscribe again. Immediately flag and re-target all clients with a 'poutcome_success' of 'success' in subsequent campaigns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ff6bc",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "- Deployment: Integrate the final Random Forest model and the 0.30 threshold into the operational CRM system to generate daily, prioritized call lists.\n",
    "- Feature Engineering: Investigate creating features that combine Duration and Campaign to capture the duration per contact efficiency.\n",
    "- Advanced Optimization: Consider deploying a model-agnostic explanation tool like SHAP to provide real-time, per-client rationale for the prediction to sales agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
